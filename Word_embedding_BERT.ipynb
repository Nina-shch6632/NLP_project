{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CReTLT9gZZBi"
      },
      "source": [
        "\n",
        "\n",
        "The goal of the notebook are three folds:\n",
        "\n",
        "\n",
        "1.   Explore word embedding\n",
        "2.   Understand contextual word embedding using BERT\n",
        "3.   Text classificaiton with both traditional machine learning methods and deep learning methods\n",
        "\n",
        "**A note about GPU**: You'd better use GPU to run it, otherwise it will be quite slow to train deep learning models.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE0gwmvro7l8"
      },
      "source": [
        "First, import the packages or modules required for this homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c4ia84G38pD"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ju3_EJHDU4j"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5VhY8Uu38pE"
      },
      "outputs": [],
      "source": [
        "pip install tf_keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDTrDzLXMX_X"
      },
      "source": [
        "## Part I: Explore Word Embedding (15%)\n",
        "\n",
        "Word embeddings are useful representation of words that capture information about word meaning as well as location. They are used as a fundamental component for downstream NLP tasks, e.g., text classification. In this part, we will explore the embeddings produced by [GloVe (global vectors for word representation)](https://nlp.stanford.edu/projects/glove/). It is simlar to Word2Vec but differs in their underlying methodology: in GloVe, word embeddings are learned based on global word-word co-occurrence statistics. Both Word2Vec and GloVe tend to produce vector-space embeddings that perform similarly in downstream NLP tasks.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlyvKW4QWHni"
      },
      "source": [
        "We first load the GloVe vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqFT4Rz0SvMD"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "# download the model and return as object ready for use\n",
        "glove_word_vectors = api.load('glove-wiki-gigaword-100')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPHjODcJ7qn-"
      },
      "source": [
        "Take a look at the vocabulary size and dimensionality of the embedding space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMAZ6Mx0Tomt",
        "outputId": "05d80b6b-83c1-4b0d-f265-e35d0a3d65e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocabulary size =  400000\n",
            "embedding dimensionality =  (100,)\n"
          ]
        }
      ],
      "source": [
        "print('vocabulary size = ', len(glove_word_vectors.index_to_key))\n",
        "print('embedding dimensionality = ', glove_word_vectors['happy'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8hGE5qYAhb1"
      },
      "source": [
        "\n",
        "What is embedding exactly?\n",
        "\n",
        "  Ans. **_In the context of natural language processing (NLP), word embeddings are numerical representations of words where words with similar meanings have similar vector representations. Word embeddings are widely used in NLP tasks such as text classification, sentiment analysis, machine translation, and more, as they provide a dense representation of words that can capture semantic relationships and similarities between words._**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd4n-3nTUp82",
        "outputId": "9133430f-e5f0-4e68-aa7f-050747739c56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.090436 ,  0.19636  ,  0.29474  , -0.47706  , -0.80436  ,\n",
              "        0.3078   , -0.55205  ,  0.58453  , -0.17056  , -0.84846  ,\n",
              "        0.19528  ,  0.23671  ,  0.46827  , -0.58977  , -0.12163  ,\n",
              "       -0.24697  , -0.072944 ,  0.17259  , -0.0485   ,  0.9527   ,\n",
              "        0.50629  ,  0.58497  , -0.19367  , -0.45459  , -0.031095 ,\n",
              "        0.51633  , -0.24052  , -0.1007   ,  0.53627  ,  0.024225 ,\n",
              "       -0.50162  ,  0.73692  ,  0.49468  , -0.34744  ,  0.89337  ,\n",
              "        0.057439 , -0.19127  ,  0.39333  ,  0.21182  , -0.89837  ,\n",
              "        0.078704 , -0.16344  ,  0.45261  , -0.41096  , -0.19499  ,\n",
              "       -0.13489  , -0.016313 , -0.021849 ,  0.17136  , -1.2413   ,\n",
              "        0.079503 , -0.91144  ,  0.35699  ,  0.36289  , -0.24934  ,\n",
              "       -2.1196   ,  0.14534  ,  0.52964  ,  0.90134  ,  0.033603 ,\n",
              "        0.022809 ,  0.70625  , -1.0362   , -0.59809  ,  0.70592  ,\n",
              "       -0.072793 ,  0.67033  ,  0.52763  , -0.47807  , -0.67374  ,\n",
              "        0.36632  , -0.38284  , -0.10349  , -0.6402   ,  0.18104  ,\n",
              "        0.82568  ,  0.066403 , -0.40791  , -0.083813 , -0.36487  ,\n",
              "        0.045362 , -0.073527 , -0.20117  ,  0.37441  , -1.4024   ,\n",
              "       -0.25605  , -0.4708   , -0.16145  , -0.87921  , -0.36325  ,\n",
              "       -0.17357  , -0.077983 ,  0.43273  ,  0.0089295, -1.0316   ,\n",
              "       -0.11589  , -0.34524  ,  0.11514  , -0.40812  ,  0.20203  ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check word embedding for 'happy'\n",
        "# You can access the embedding of a word with glove_word_vectors[word] if word\n",
        "# is in the vocabulary\n",
        "glove_word_vectors['happy']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4fKXR-gUQUl"
      },
      "source": [
        "With word embeddings learned from GloVe or Word2Vec, words with similar semantic meanings tend to have vectors that are close together. Please code and calculate the **cosine similarities** between words based on their embeddings (i.e., word vectors).\n",
        "\n",
        "For each of the following words in occupation, compute its cosine similarty to 'woman' and its similarity to 'man' and check which gender is more similar.\n",
        "\n",
        "*occupation = {homemaker, nurse, receptionist, librarian, socialite, hairdresser, nanny, bookkeeper, stylist, housekeeper, maestro, skipper, protege, philosopher, captain, architect, financier, warrior, broadcaster, magician}*\n",
        "\n",
        "**Inline Question #1:**\n",
        "- Fill in the table below with cosine similarities between words in occupation list and {woman, man}. Please show only two digits after decimal.\n",
        "- Which words are more similar to 'woman' than to 'man'?\n",
        "\n",
        "  **_['homemaker', 'nurse', 'receptionist', 'librarian', 'socialite', 'hairdresser', 'nanny', 'bookkeeper', 'stylist', 'housekeeper']_**\n",
        "- Which words are more similar to 'man' than to 'woman'?\n",
        "\n",
        "  **_['maestro', 'skipper', 'protege', 'philosopher', 'captain', 'architect', 'financier', 'warrior', 'broadcaster', 'magician']_**\n",
        "- Do you see any issue here? What do you think might cause these issues?\n",
        "\n",
        "    **_The issue here is that the results seem to reinforce gender stereotypes, where traditionally female-associated occupations like \"homemaker,\" \"nurse,\" and \"hairdresser\" are more similar to the word \"woman,\" while traditionally male-associated occupations like \"maestro,\" \"captain,\" and \"warrior\" are more similar to the word \"man.\"_**\n",
        "    \n",
        "    **_These issues likely arise from biases present in the training data used to create the GloVe word embeddings. If the text data used to train the word embeddings contains biases or stereotypical associations, these biases will be reflected in the resulting word embeddings. If the training data lacks diverse representations of different genders in various occupations._**\n",
        "\n",
        "**Your Answer:**\n",
        "\n",
        "| `similarity`|    woman  |      man     |\n",
        "|-------------|-----------|--------------|\n",
        "| homemaker   |   0.43    |    0.24      |\n",
        "| nurse       |   0.61    |    0.46      |\n",
        "| receptionist|   0.34    |    0.19      |\n",
        "| librarian   |   0.34    |    0.23      |\n",
        "| socialite   |   0.42    |    0.27      |\n",
        "| hairdresser |   0.39    |    0.26      |\n",
        "| nanny       |   0.36    |    0.29      |\n",
        "| bookkeeper  |   0.21    |    0.14      |\n",
        "| stylist     |   0.31    |    0.25      |\n",
        "| housekeeper |   0.46    |    0.31      |\n",
        "| maestro     |  -0.02    |    0.14      |\n",
        "| skipper     |   0.15    |    0.34      |\n",
        "| protege     |   0.12    |    0.20      |\n",
        "| philosopher |   0.23    |    0.28      |\n",
        "| captain     |   0.31    |    0.53      |\n",
        "| architect   |   0.22    |    0.30      |\n",
        "| financier   |   0.14    |    0.26      |\n",
        "| warrior     |   0.39    |    0.51      |\n",
        "| broadcaster |   0.23    |    0.25      |\n",
        "| magician    |   0.27    |    0.38      |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8r9f1FTsn5e",
        "outputId": "3ff2feae-c27b-49d0-c21a-6375c71cddad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Occupation: homemaker\n",
            "Similarity to 'woman': 0.43\n",
            "Similarity to 'man': 0.24\n",
            "\n",
            "Occupation: nurse\n",
            "Similarity to 'woman': 0.61\n",
            "Similarity to 'man': 0.46\n",
            "\n",
            "Occupation: receptionist\n",
            "Similarity to 'woman': 0.34\n",
            "Similarity to 'man': 0.19\n",
            "\n",
            "Occupation: librarian\n",
            "Similarity to 'woman': 0.34\n",
            "Similarity to 'man': 0.23\n",
            "\n",
            "Occupation: socialite\n",
            "Similarity to 'woman': 0.42\n",
            "Similarity to 'man': 0.27\n",
            "\n",
            "Occupation: hairdresser\n",
            "Similarity to 'woman': 0.39\n",
            "Similarity to 'man': 0.26\n",
            "\n",
            "Occupation: nanny\n",
            "Similarity to 'woman': 0.36\n",
            "Similarity to 'man': 0.29\n",
            "\n",
            "Occupation: bookkeeper\n",
            "Similarity to 'woman': 0.21\n",
            "Similarity to 'man': 0.14\n",
            "\n",
            "Occupation: stylist\n",
            "Similarity to 'woman': 0.31\n",
            "Similarity to 'man': 0.25\n",
            "\n",
            "Occupation: housekeeper\n",
            "Similarity to 'woman': 0.46\n",
            "Similarity to 'man': 0.31\n",
            "\n",
            "Occupation: maestro\n",
            "Similarity to 'woman': -0.02\n",
            "Similarity to 'man': 0.14\n",
            "\n",
            "Occupation: skipper\n",
            "Similarity to 'woman': 0.15\n",
            "Similarity to 'man': 0.34\n",
            "\n",
            "Occupation: protege\n",
            "Similarity to 'woman': 0.12\n",
            "Similarity to 'man': 0.20\n",
            "\n",
            "Occupation: philosopher\n",
            "Similarity to 'woman': 0.23\n",
            "Similarity to 'man': 0.28\n",
            "\n",
            "Occupation: captain\n",
            "Similarity to 'woman': 0.31\n",
            "Similarity to 'man': 0.53\n",
            "\n",
            "Occupation: architect\n",
            "Similarity to 'woman': 0.22\n",
            "Similarity to 'man': 0.30\n",
            "\n",
            "Occupation: financier\n",
            "Similarity to 'woman': 0.14\n",
            "Similarity to 'man': 0.26\n",
            "\n",
            "Occupation: warrior\n",
            "Similarity to 'woman': 0.39\n",
            "Similarity to 'man': 0.51\n",
            "\n",
            "Occupation: broadcaster\n",
            "Similarity to 'woman': 0.23\n",
            "Similarity to 'man': 0.25\n",
            "\n",
            "Occupation: magician\n",
            "Similarity to 'woman': 0.27\n",
            "Similarity to 'man': 0.38\n",
            "\n"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #                                                          #\n",
        "################################################################################\n",
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(x, y):\n",
        "    dot = np.dot(x, y)\n",
        "    norm_x = np.linalg.norm(x)\n",
        "    norm_y = np.linalg.norm(y)\n",
        "\n",
        "    cos_sim = dot / (norm_x * norm_y)\n",
        "\n",
        "    return cos_sim\n",
        "\n",
        "occupation = ['homemaker', 'nurse', 'receptionist', 'librarian', 'socialite', 'hairdresser', 'nanny', 'bookkeeper', 'stylist', 'housekeeper', 'maestro', 'skipper', 'protege', 'philosopher', 'captain', 'architect', 'financier', 'warrior', 'broadcaster', 'magician']\n",
        "\n",
        "similarity_to_woman = {}\n",
        "similarity_to_man = {}\n",
        "\n",
        "for i in occupation:\n",
        "    x = glove_word_vectors[i]\n",
        "    y_woman = glove_word_vectors['woman']\n",
        "    y_man = glove_word_vectors['man']\n",
        "\n",
        "    similarity_to_woman[i] = cosine_similarity(x, y_woman)\n",
        "    similarity_to_man[i] = cosine_similarity(x, y_man)\n",
        "\n",
        "for i in occupation:\n",
        "    print(f\"Occupation: {i}\")\n",
        "    print(f\"Similarity to 'woman': {similarity_to_woman[i]:.2f}\")\n",
        "    print(f\"Similarity to 'man': {similarity_to_man[i]:.2f}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "for i in occupation:\n",
        "  similarity_to_woman[i] = cosine_similarity(x, y_woman)\n",
        "  similarity_to_man[i] = cosine_similarity(x, y_man)\n",
        "  if similarity_to_woman[i] > similarity_to_man[i]:\n",
        "    print(i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JON3b6nzUUmL",
        "outputId": "0c24c6a1-aec0-42ae-cbb6-0be7d3b3acad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['homemaker', 'nurse', 'receptionist', 'librarian', 'socialite', 'hairdresser', 'nanny', 'bookkeeper', 'stylist', 'housekeeper']\n",
            "['maestro', 'skipper', 'protege', 'philosopher', 'captain', 'architect', 'financier', 'warrior', 'broadcaster', 'magician']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "similar_to_woman=[]\n",
        "\n",
        "for i in occupation:\n",
        "    similarity_to_woman = cosine_similarity(glove_word_vectors[i], glove_word_vectors['woman'])\n",
        "    similarity_to_man = cosine_similarity(glove_word_vectors[i], glove_word_vectors['man'])\n",
        "    if similarity_to_woman > similarity_to_man:\n",
        "      similar_to_woman.append(i)\n",
        "      #print(f'Words are more similar to woman than to man: {i}')\n",
        "\n",
        "print(similar_to_woman)\n",
        "\n",
        "similar_to_man=[]\n",
        "for i in occupation:\n",
        "    similarity_to_woman = cosine_similarity(glove_word_vectors[i], glove_word_vectors['woman'])\n",
        "    similarity_to_man = cosine_similarity(glove_word_vectors[i], glove_word_vectors['man'])\n",
        "    if similarity_to_woman < similarity_to_man:\n",
        "      similar_to_man.append(i)\n",
        "      #print(f'Words are more similar to man than to woman: {i}')\n",
        "print(similar_to_man)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tS-rk_0htP1"
      },
      "source": [
        "## Part II Understand contextual word embedding using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhiqrefnhyzl"
      },
      "source": [
        "A big difference between Word2Vec and BERT is that Word2Vec learns context-free word representations, i.e., the embedding for 'orange' is the same in \"I love eating oranges\" and in \"The sky turned orange\". BERT, on the other hand, produces contextual word presentations, i.e., embeddings for the same word in different contexts are different.\n",
        "\n",
        "For example, let us compare the context-based embedding vectors for 'orange' in the following three sentences using Bert:\n",
        "* \"I love eating oranges\"\n",
        "* \"My favorite fruits are oranges and apples\"\n",
        "* \"The sky turned orange\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krMUN1bXEHMu"
      },
      "source": [
        "Same as in \"Lab 5 BERT\", we use the BERT model and tokenizer from the Huggingface transformer library ([1](https://huggingface.co/course/chapter1/1), [2](https://huggingface.co/docs/transformers/quicktour))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE1bsvtolEz4",
        "outputId": "db13f734-ee51-4347-814f-2d9cd16b4047"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.39.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "4.39.3\n"
          ]
        }
      ],
      "source": [
        "# Note that we need to install the latest version of transformers\n",
        "# Due to problems we encountered in class and reported here\n",
        "# https://discuss.huggingface.co/t/pretrain-model-not-accepting-optimizer/76209\n",
        "# https://github.com/huggingface/transformers/issues/29470\n",
        "\n",
        "!pip install --upgrade transformers\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEHtbdMLlS-Q",
        "outputId": "1e21b181-ad8d-4b64-cfb4-757676656f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, TFBertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kptKqkSEjAA"
      },
      "source": [
        "We use the 'bert-base-cased' from Huggingface as the underlying BERT model and the associated tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "8e13cd7a4e584ca9b0c91f92df5c7673",
            "c6888f54b79c46fda753b97d17468ac2",
            "5f750b91de594832bbc1450331db3b85",
            "be55df80a2734f9db571ba06e1c9776d",
            "54d458c52405443eb07eea835efb68b5",
            "696d9a10019d4a398691f22c672e5582",
            "c0a809f53ecd47839cd9838e845618e0",
            "7ff600d4948f4aabacb8fcd82b1c6bc4",
            "ab4bb3e86d9f4033a4b955aa8154a3d5",
            "551b93d69cc84364807cb02a161d7180",
            "baa767a7f5eb4b4180f651ed8ede4f7b",
            "8fa34397663e4c47b58c65c5811d0c92",
            "20cb9a60a488402e8b8b4ede244c689b",
            "45041e14756141f7a44f7006002231b8",
            "05f44adfb4964ceaa3866ecbcfe93d63",
            "6a68d259fa2a4e1eb0c18231fea81021",
            "4fde371c6e1c42ce9368ccbbc0f1f955",
            "3782cd35ae4f451b9035083937103a49",
            "714041e86d6c4c4e8a6b334ab92f74f3",
            "065fa71c1ac44ce4999d75ad64993f5e",
            "567958bbdc884b2886eb5dc0afbc9606",
            "4531a592df7e498681cc9f17da06c0cd",
            "7d019b5368aa454d886d042e7841cd6e",
            "ffd39daf4f4942ed8e3239086ba17ce8",
            "263211072c3a4244a7651fe917a720e2",
            "4afd76e8ccb841cc990a8bbd9eff7297",
            "098be2c679f04237a6b532c192986e46",
            "8184956211b14516989815ffc5d959d4",
            "5308f11014ee447ebb317e735022e176",
            "778f819277e74ecb9c03f64fa670ef40",
            "fde7a6747ac94b1e9897535c32669502",
            "2bb34f1837344ec390fe7ce1ee846c41",
            "20407c199d98484c8c5b8421bb28e729",
            "7ddd9b1927b34f01acbf622847a17f5e",
            "1695467872df4de1ab3f9005313b238f",
            "c794b0da55ab4161b6c324ceb3b3da40",
            "08ce1ff69e954d5bacc6b94edf9344d9",
            "545f44b79ed44d1ba762b3df7b85fe55",
            "64b27509450046de923d6f510c32f408",
            "470049052bc74033ae8a56c833a9fbed",
            "987a6b3c03b543c583b366cf34ab1021",
            "3c45b91044d24aa488c6cd73183ed272",
            "90b6b9f984e74f1d8698f29a039e0fac",
            "492f34b402444c14afaedb7ff1be464e",
            "c40a2c1c00c94b5d92409a1b3764f28f",
            "263f8f6e0fde4d228c7bb150fc23ddf2",
            "75b6a7cf18e64ac1b80c889bed81f340",
            "9b79a91e90824c42834b4957b74c3d7e",
            "bf0fb1038d9940f1b283bd40a60341d0",
            "67d0fe0fac824a4e897d32772d514f20",
            "a4607b818f99416195d9a927654738ca",
            "cb7078474f1c48afac5354dd1a39b47f",
            "7bda0f1423cd4ba98e62a76b40375b00",
            "2d9356996edb4325a2e1fb37cdd086a0",
            "69b625e232d148f98f1709ae07ee619c",
            "a601cad5ddd34f8c9f7e2ed9fa6cf1ef",
            "12f6561a3cc9443eacd98135557848fc",
            "35c02b16109d452aa3d60e27b4052690",
            "6e2883dcb6db453c8fa5dc0004ba408b",
            "93f62ecf74014636990af18e6f782945"
          ]
        },
        "id": "VaXbeG1TmukM",
        "outputId": "0b075d1f-d986-4056-9a09-474dc8420762"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a601cad5ddd34f8c9f7e2ed9fa6cf1ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12f6561a3cc9443eacd98135557848fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35c02b16109d452aa3d60e27b4052690",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e2883dcb6db453c8fa5dc0004ba408b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93f62ecf74014636990af18e6f782945",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb_U7kyMEroc"
      },
      "outputs": [],
      "source": [
        "example_sentences = [\"I love eating oranges\",\n",
        "                     \"My favorite fruits are oranges and apples\",\n",
        "                     \"The sky turned orange\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftt2mbDnEs6I"
      },
      "source": [
        "Let us start by tokenizing the example sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4VMvgnCE5MQ",
        "outputId": "c2f28688-e7c6-4a44-f562-d8acc5b9f219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'love', 'eating', 'orange', '##s']\n",
            "['My', 'favorite', 'fruits', 'are', 'orange', '##s', 'and', 'apples']\n",
            "['The', 'sky', 'turned', 'orange']\n"
          ]
        }
      ],
      "source": [
        "# Check how Bert tokenize each sentence\n",
        "# This helps us identify the location of 'orange' in the tokenized vector\n",
        "for sen in example_sentences:\n",
        "  print(bert_tokenizer.tokenize(sen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDDKRE1RE8OK"
      },
      "source": [
        "Notice that the prefix '##' indicates that the token is a continuation of the previous one. This also helps us identify location of 'orange' in the tokenized vector, e.g., 'orange' is the 4th token in the first sentence. Note that here the tokenize() function just splits a text into words, and doesn't add a 'CLS' (classification token) or a 'SEP' (separation token) to the text.\n",
        "\n",
        "Next, we use the tokenizer to transfer the example sentences to input that the Bert model expects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0XgIyKGlqy5",
        "outputId": "c4851516-25a5-41e1-83fc-bae4f19a375f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
              "array([[  101,   146,  1567,  5497,  5925,  1116,   102,     0,     0,\n",
              "            0],\n",
              "       [  101,  1422,  5095, 11669,  1132,  5925,  1116,  1105, 22888,\n",
              "          102],\n",
              "       [  101,  1109,  3901,  1454,  5925,   102,     0,     0,     0,\n",
              "            0]])>, 'token_type_ids': <tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(3, 10), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])>}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_inputs = bert_tokenizer(example_sentences,\n",
        "                             padding=True,\n",
        "                             return_tensors='tf')\n",
        "\n",
        "bert_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrzU61KaI3Of"
      },
      "source": [
        "So there are actually three outputs: the input ids (starting with '101' for the '[CLS]' token), the token_type_ids which are usefull when one has distinct segments, and the attention masks which are used to mask out padding tokens.\n",
        "\n",
        "Please refer to our Lab 4 for more details about input_ids, token_type_ids, and attention_masks.\n",
        "\n",
        "More resources:\n",
        "*    https://huggingface.co/docs/transformers/preprocessing\n",
        "*    https://huggingface.co/docs/transformers/tokenizer_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FwSZzTBJFC3"
      },
      "source": [
        "Now, let us get the BERT encoding of our example sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP4sg23im6wd",
        "outputId": "1783b064-e0ab-4c39-8134-9718cf36c1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of first output: \t\t (3, 10, 768)\n",
            "shape of second output: \t (3, 768)\n"
          ]
        }
      ],
      "source": [
        "bert_outputs = bert_model(bert_inputs)\n",
        "\n",
        "print('shape of first output: \\t\\t', bert_outputs[0].shape)\n",
        "print('shape of second output: \\t', bert_outputs[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1LmkPOWJPJp"
      },
      "source": [
        "There are two outputs here: one with dimensions [3, 10, 768] and one with [3, 768]. The first one [batch_size, sequence_length, embedding_size] is the output of the last layer of the Bert model and are the contextual embeddings of the words in the input sequence. The second output [batch_size, embedding_size] is the embedding of the first token of the sequence (i.e., classification token).\n",
        "\n",
        "Note you can also get the first output through bert_output.last_hidden_state (see below, also check https://huggingface.co/docs/transformers/v4.16.2/en/model_doc/bert#transformers.TFBertModel)\n",
        "\n",
        "We need the first output to get contextualized embeddings for 'orange' in each sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ8FgzC1KWxg",
        "outputId": "4f681dec-f647-4a55-c320-76a9552d29b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10, 768), dtype=float32, numpy=\n",
              "array([[[ 0.72526133,  0.10203083, -0.24569108, ..., -0.04899119,\n",
              "          0.39186496,  0.02921054],\n",
              "        [ 0.22793137,  0.12613058,  0.12215026, ...,  0.31073734,\n",
              "         -0.13684127,  0.33928937],\n",
              "        [ 0.11651945,  0.20991722, -0.62462795, ...,  0.7515276 ,\n",
              "         -0.7327964 ,  0.05906113],\n",
              "        ...,\n",
              "        [-0.10604811, -0.1910808 , -0.11248238, ...,  0.13676174,\n",
              "          0.0700286 ,  0.19438452],\n",
              "        [ 0.05706045, -0.29356378, -0.03861157, ...,  0.01285999,\n",
              "          0.27537084,  0.15846887],\n",
              "        [ 0.24304445, -0.06842123,  0.09176344, ..., -0.161979  ,\n",
              "          0.24152774,  0.00447912]],\n",
              "\n",
              "       [[ 0.54033554, -0.11092855, -0.12229536, ..., -0.16148904,\n",
              "          0.23800467, -0.03805562],\n",
              "        [-0.08707761, -0.13345687,  0.35856643, ..., -0.06155135,\n",
              "          0.13525176,  0.38933346],\n",
              "        [-0.01516274, -0.41845623, -0.13030319, ...,  0.12552255,\n",
              "         -0.4938446 ,  0.521323  ],\n",
              "        ...,\n",
              "        [ 0.2822883 , -0.2443214 , -0.20268017, ..., -0.09836684,\n",
              "          0.05036386,  0.19456698],\n",
              "        [ 0.41708237,  0.19513237,  0.28022492, ..., -0.45395684,\n",
              "          0.25012198,  0.04929541],\n",
              "        [ 0.99297726,  0.24790019, -0.20914587, ..., -0.6324764 ,\n",
              "          0.18984383, -0.61011493]],\n",
              "\n",
              "       [[ 0.10601693,  0.06181864,  0.04633281, ..., -0.30906737,\n",
              "          0.23271656, -0.13493463],\n",
              "        [-0.2122451 , -0.5082531 ,  0.28352916, ..., -0.06875607,\n",
              "         -0.11457989,  0.5859629 ],\n",
              "        [ 0.08372124,  0.17443301,  0.03233524, ..., -0.2160287 ,\n",
              "         -0.4203534 ,  0.16849408],\n",
              "        ...,\n",
              "        [-0.40330526, -0.5378848 ,  0.03425169, ..., -0.0472177 ,\n",
              "          0.1252183 ,  0.15385357],\n",
              "        [-0.2019094 , -0.42219824,  0.01825918, ..., -0.4031477 ,\n",
              "          0.40740585,  0.04357285],\n",
              "        [-0.1814523 , -0.3931386 ,  0.059618  , ..., -0.31333318,\n",
              "          0.43819067,  0.095341  ]]], dtype=float32)>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_outputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikEVh5PAJ05j",
        "outputId": "3b2159fe-15a1-4968-aa65-cc1c08fb8976"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10, 768), dtype=float32, numpy=\n",
              "array([[[ 0.72526133,  0.10203083, -0.24569108, ..., -0.04899119,\n",
              "          0.39186496,  0.02921054],\n",
              "        [ 0.22793137,  0.12613058,  0.12215026, ...,  0.31073734,\n",
              "         -0.13684127,  0.33928937],\n",
              "        [ 0.11651945,  0.20991722, -0.62462795, ...,  0.7515276 ,\n",
              "         -0.7327964 ,  0.05906113],\n",
              "        ...,\n",
              "        [-0.10604811, -0.1910808 , -0.11248238, ...,  0.13676174,\n",
              "          0.0700286 ,  0.19438452],\n",
              "        [ 0.05706045, -0.29356378, -0.03861157, ...,  0.01285999,\n",
              "          0.27537084,  0.15846887],\n",
              "        [ 0.24304445, -0.06842123,  0.09176344, ..., -0.161979  ,\n",
              "          0.24152774,  0.00447912]],\n",
              "\n",
              "       [[ 0.54033554, -0.11092855, -0.12229536, ..., -0.16148904,\n",
              "          0.23800467, -0.03805562],\n",
              "        [-0.08707761, -0.13345687,  0.35856643, ..., -0.06155135,\n",
              "          0.13525176,  0.38933346],\n",
              "        [-0.01516274, -0.41845623, -0.13030319, ...,  0.12552255,\n",
              "         -0.4938446 ,  0.521323  ],\n",
              "        ...,\n",
              "        [ 0.2822883 , -0.2443214 , -0.20268017, ..., -0.09836684,\n",
              "          0.05036386,  0.19456698],\n",
              "        [ 0.41708237,  0.19513237,  0.28022492, ..., -0.45395684,\n",
              "          0.25012198,  0.04929541],\n",
              "        [ 0.99297726,  0.24790019, -0.20914587, ..., -0.6324764 ,\n",
              "          0.18984383, -0.61011493]],\n",
              "\n",
              "       [[ 0.10601693,  0.06181864,  0.04633281, ..., -0.30906737,\n",
              "          0.23271656, -0.13493463],\n",
              "        [-0.2122451 , -0.5082531 ,  0.28352916, ..., -0.06875607,\n",
              "         -0.11457989,  0.5859629 ],\n",
              "        [ 0.08372124,  0.17443301,  0.03233524, ..., -0.2160287 ,\n",
              "         -0.4203534 ,  0.16849408],\n",
              "        ...,\n",
              "        [-0.40330526, -0.5378848 ,  0.03425169, ..., -0.0472177 ,\n",
              "          0.1252183 ,  0.15385357],\n",
              "        [-0.2019094 , -0.42219824,  0.01825918, ..., -0.4031477 ,\n",
              "          0.40740585,  0.04357285],\n",
              "        [-0.1814523 , -0.3931386 ,  0.059618  , ..., -0.31333318,\n",
              "          0.43819067,  0.095341  ]]], dtype=float32)>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_outputs.last_hidden_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1q3hM3fNiG-"
      },
      "source": [
        "Now, we get the embeddings of 'orange' in each sentence by simply finding the 'orange'-token positions in the embedding output and extract the proper components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw1q9s0ZnBkl"
      },
      "outputs": [],
      "source": [
        "orange_1 = bert_outputs[0][0, 4]\n",
        "orange_2 = bert_outputs[0][1, 5]\n",
        "orange_3 = bert_outputs[0][2, 4]\n",
        "\n",
        "oranges = [orange_1, orange_2, orange_3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kShV7UfOQMSN"
      },
      "source": [
        "We calculate pair-wise cosine similarities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-YfDwiinRf-"
      },
      "outputs": [],
      "source": [
        "def cosine_similarities(vecs):\n",
        "    for v_1 in vecs:\n",
        "        similarities = ''\n",
        "        for v_2 in vecs:\n",
        "            similarities += ('\\t' + str(np.dot(v_1, v_2)/\n",
        "                np.sqrt(np.dot(v_1, v_1) * np.dot(v_2, v_2)))[:4])\n",
        "        print(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oLzuz8znTBO",
        "outputId": "ccb2fb6a-1f88-45ef-de35-8a0d7fa84240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t1.0\t0.91\t0.69\n",
            "\t0.91\t1.0\t0.66\n",
            "\t0.69\t0.66\t1.0\n"
          ]
        }
      ],
      "source": [
        "cosine_similarities(oranges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB1BRbygpGBM"
      },
      "source": [
        "The similarity metrics make sense. The 'orange' in \"The sky turned orange\" is different from the rest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enG4ADZaqbvm"
      },
      "source": [
        "Next, please compare the contextual embedding vectors of 'bank' in the following four sentences:\n",
        "\n",
        "\n",
        "*   \"I need to bring my money to the bank today\"\n",
        "*   \"I will need to bring my money to the bank tomorrow\"\n",
        "*   \"I had to bank into a turn\"\n",
        "*   \"The bank teller was very nice\"\n",
        "\n",
        "\n",
        "**Inline Question #1:**\n",
        "\n",
        "- Please calculate the pair-wise cosine similarities between 'bank' in the four sentences and fill in the table below. (Note, bank_i represent bank in the i_th sentence)\n",
        "- Please explain the results. Does it make sense?\n",
        "  \n",
        "  ** _Overall, the results seem reasonable.The \"bank\" in the third sentence. The cosine similarity values are lower (0.59, 0.59, 0.62) compared to the other contexts, indicating less similarity with the other contexts. This makes sense because the word \"bank\" is used in a different sense here (possibly referring to a maneuver in driving: cause to tilt sideways in making a turn.)._\n",
        "  \n",
        "  ** _The occurrences of \"bank\" in the first, second, and fourth sentences indeed correspond to each other in the context, as they all relate to financial institutions. The cosine similarity values for these contexts are relatively high, indicating that the contextual embeddings of \"bank\" in these sentences have a considerable degree of similarity with each other._\n",
        "\n",
        "**Your Answer:**\n",
        "\n",
        "| `similarity`|  bank_1  |  bank_2  |  bank_3  |  bank_4  |\n",
        "|-------------|----------|----------|----------|----------|\n",
        "| bank_1      |   1.0    |   0.99   |   0.59   |   0.86   |\n",
        "| bank_2      |   0.99   |   1.0    |   0.59   |   0.87   |\n",
        "| bank_3      |   0.59   |   0.59   |   1.0    |   0.62   |\n",
        "| bank_4      |   0.86   |   0.87   |   0.62   |   1.0    |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WppqV6v_qbHu",
        "outputId": "9e353605-7903-45cd-f2a9-71c20e3a5f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'need', 'to', 'bring', 'my', 'money', 'to', 'the', 'bank', 'today']\n",
            "['I', 'will', 'need', 'to', 'bring', 'my', 'money', 'to', 'the', 'bank', 'tomorrow']\n",
            "['I', 'had', 'to', 'bank', 'into', 'a', 'turn']\n",
            "['The', 'bank', 'tell', '##er', 'was', 'very', 'nice']\n"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #                                                              #\n",
        "################################################################################\n",
        "bank_sentences = [\"I need to bring my money to the bank today\",\n",
        "                  \"I will need to bring my money to the bank tomorrow\",\n",
        "                     \"I had to bank into a turn\",\n",
        "                  \"The bank teller was very nice\"]\n",
        "\n",
        "for sen in bank_sentences:\n",
        "  print(bert_tokenizer.tokenize(sen))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CtC8H1Y78Kx"
      },
      "outputs": [],
      "source": [
        "bert_inputs = bert_tokenizer(bank_sentences,\n",
        "                             padding=True,\n",
        "                             return_tensors='tf')\n",
        "\n",
        "bert_outputs = bert_model(bert_inputs)\n",
        "\n",
        "bank_1 = bert_outputs[0][0, 9]\n",
        "bank_2 = bert_outputs[0][1, 10]\n",
        "bank_3 = bert_outputs[0][2, 4]\n",
        "bank_4 = bert_outputs[0][3, 2]\n",
        "\n",
        "bank = [bank_1, bank_2, bank_3, bank_4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43WlD6468Q9B",
        "outputId": "c5845f5c-e8bc-4d89-d7ed-5cf8eb442a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t1.0\t0.99\t0.59\t0.86\n",
            "\t0.99\t1.0\t0.59\t0.87\n",
            "\t0.59\t0.59\t1.0\t0.62\n",
            "\t0.86\t0.87\t0.62\t1.0\n"
          ]
        }
      ],
      "source": [
        "cosine_similarities(bank)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muJRiiu1hY4g"
      },
      "source": [
        "## Part III Text classification\n",
        "\n",
        "In this part, you will build text classifiers that try to infer whether tweets from [@realDonaldTrump](https://twitter.com/realDonaldTrump) were written by Trump himself or by a staff person.\n",
        "This is an example of binary classification on a text dataset.\n",
        "\n",
        "It is known that Donald Trump uses an Android phone, and it has been observed that some of his tweets come from Android while others come from other devices (most commonly iPhone). It is widely believed that Android tweets are written by Trump himself, while iPhone tweets are written by other staff. For more information, you can read this [blog post by David Robinson](http://varianceexplained.org/r/trump-tweets/), written prior to the 2016 election, which finds a number of differences in the style and timing of tweets published under these two devices. (Some tweets are written from other devices, but for simplicity the dataset for this assignment is restricted to these two.)\n",
        "\n",
        "This is a classification task known as \"authorship attribution\", which is the task of inferring the author of a document when the authorship is unknown. We will see how accurately this can be done with linear classifiers using word features.\n",
        "\n",
        "You might find it familiar: Yes! We are using the same data set as your homework 2 from MSBC 5180."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qrPDJHAVRSi"
      },
      "source": [
        "### Tasks\n",
        "\n",
        "In this section, you will build two text classifiers: one with a traditional machine learning method that you studied in MSBC.5190 and one with a deep learning method.\n",
        "\n",
        "\n",
        "*   For the first classifier, you can use any non-deep learning based methods. You can use your solution to Homework 2 of MSBC 5180 here.\n",
        "*   For the second classifier, you may try the following methods\n",
        "    *    Fine-tune BERT (similar to our Lab 5 Fine-tune BERT for Sentiment Analysis)\n",
        "    *    Use pre-trained word embedding (useful to check: https://keras.io/examples/nlp/pretrained_word_embeddings/)\n",
        "    *    Train a deep neural network (e.g., CNN, RNN, Bi-LSTM) from scratch, similar to notebooks from our textbook:\n",
        "        *    https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/dense_sentiment_classifier.ipynb\n",
        "        *    https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/convolutional_sentiment_classifier.ipynb\n",
        "        *    https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/rnn_sentiment_classifier.ipynb\n",
        "        *    https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/lstm_sentiment_classifier.ipynb\n",
        "        *    https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/bi_lstm_sentiment_classifier.ipynb\n",
        "    *   There are also lots of useful resources on Keras website: https://keras.io/examples/nlp/\n",
        "\n",
        "You may want to split the current training data to train and validation to help model selection. Please do not use test data for model selection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huC0ZChevyi2"
      },
      "source": [
        "### Load the Data Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbQbaofDdKJW"
      },
      "source": [
        "#### Sample code to load raw text###\n",
        "\n",
        "Please download `tweets.train.tsv` and `tweets.test.tsv` from Canvas (Module Assignment) and upload them to Google Colab. Here we load raw text data to text_train and text_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0LtpZn3mtQW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#training set\n",
        "df_train = pd.read_csv('tweets.train.tsv', sep='\\t', header=None)\n",
        "\n",
        "text_train = df_train.iloc[0:, 1].values.tolist()\n",
        "Y_train = df_train.iloc[0:, 0].values\n",
        "# convert to binary labels (0 and 1)\n",
        "y_train = np.array([1 if v == 'Android' else 0 for v in Y_train])\n",
        "\n",
        "df_test = pd.read_csv('tweets.test.tsv', sep='\\t', header=None)\n",
        "text_test = df_test.iloc[0:, 1].values.tolist()\n",
        "Y_test = df_test.iloc[0:, 0].values\n",
        "# convert to binary labels (0 and 1)\n",
        "y_test = np.array([1 if v == 'Android' else 0 for v in Y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMNf2rx8xrBR",
        "outputId": "a6254e08-7b47-496e-aad7-b500c40be6a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(text_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiwE7oviUIzw"
      },
      "source": [
        "Let us take a quick look of some training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7x5n1i4U1Ty",
        "outputId": "0749bb98-ad95-48e7-8781-79c1ff64b42f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"My statement as to what's happening in Sweden was in reference to a story that was broadcast on _USERNAME_ concerning immigrants & Sweden.\",\n",
              " 'Will be having many meetings this weekend at The Southern White House. Big 5:00 P.M. speech in Melbourne, Florida. A lot to talk about!',\n",
              " \"Don't believe the main stream (fake news) media.The White House is running VERY WELL. I inherited a MESS and am in the process of fixing it.\",\n",
              " 'Looking forward to the Florida rally tomorrow. Big crowd expected!',\n",
              " \"'One of the most effective press conferences I've ever seen!' says Rush Limbaugh. Many agree.Yet FAKE MEDIA calls it differently! Dishonest\"]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_train[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MemhkdSU3Uk",
        "outputId": "7ca87120-d3b5-42c6-c7c9-af407e6b808f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcuUb7duU-dL"
      },
      "source": [
        "#### Sample code to preprocess data for BERT (only needed if you decide to fine-tune BERT) ####\n",
        "\n",
        "The pre-processing step is similar to Lab 5.\n",
        "\n",
        "Feel free to dispose it if you want to preprocess the data differently and use methods other than BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26uqOprdmuj8"
      },
      "outputs": [],
      "source": [
        "# The longest text in the data is 75 and we use it as the max_length\n",
        "max_length = 75\n",
        "x_train = bert_tokenizer(text_train,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = np.array([1 if v == 'Android' else 0 for v in Y_train])\n",
        "\n",
        "x_test = bert_tokenizer(text_test,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = np.array([1 if v == 'Android' else 0 for v in Y_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjHmp3nZPL7"
      },
      "source": [
        "### 1: A traditional machine learning approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-pI4oKqZapr"
      },
      "source": [
        "Please implement your text classifier using a traditional machine learning method.\n",
        "\n",
        "**Inline Question #1:**\n",
        "- What machine leaning model did you use?  **_Logistic Regression Classifier_**\n",
        "- What are the features used in this model?  **_TF-IDF (Term Frequency-Inverse Document Frequency) vectors_**\n",
        "- What is the model's performance in the test data?  **_Test accuracy: 0.89_**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkq6TnWfZbSe",
        "outputId": "07ba7c52-8866-44ba-a60e-c1cb825f8224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.92\n",
            "Test Accuracy: 0.89\n"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "################################################################################\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "pipeline.fit(text_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Predict on training data\n",
        "y_train_pred = pipeline.predict(text_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "# testing data\n",
        "y_pred = pipeline.predict(text_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L2f5VzUZThM"
      },
      "source": [
        "### 2: A deep learning apporach\n",
        "\n",
        "Please implement your text classifier using a deep learning method\n",
        "\n",
        "**Inline Question #1:**\n",
        "- What deep leaning model did you use?\n",
        "  \n",
        "  **_BERT (Bidirectional Encoder Representations from Transformers), which is a pre-trained language model._**\n",
        "- Please briefly explain the input, output, and layers (e.g., what does each layer do) of your model.\n",
        "\n",
        "  * **_Input: The input to the BERT model is a sequence of tokens, which are generated using a tokenizer. Each token represents a word or a subword (depending on the tokenization strategy used). These tokens are converted into embeddings, which are numerical representations of the words or subwords._**\n",
        "  * **_Output: The output of the BERT model for a classification task is a single scalar value representing the classification score. This score indicates the model's confidence in assigning the input sequence to a particular class. In binary classification tasks like the one specified in the code (num_labels=1), the output score represents the probability of the input sequence belonging to one of the two classes._**\n",
        "  * **_Layer: The BERT model is a transformer-based architecture with several layers:_**\n",
        "      1. **_Embedding Layer: converts the input tokens into dense vector representations (embeddings)._**\n",
        "      2. **_Encoder Layers: The BERT model has multiple encoder layers, each consisting of multi-head self-attention mechanisms and feed-forward neural networks. Capturing the contextual relationships between tokens in the input sequence._**\n",
        "      3. **_Pooler Layer: combines the output representations from the encoder layers to provide a single vector representation for the entire input sequence._**\n",
        "      4. **_Classification Layer: A fully connected layer is added on top of the pooler layer to produce the final output for the sequence classification task._**\n",
        "\n",
        "\n",
        "- What is the model's performance in the test data?\n",
        "   **_Test accuracy: 0.92432_**\n",
        "- Is it better or worse than Solution 1? What might be the cause?\n",
        "  \n",
        "  **_Model performance of Bert is better than Solution 1. BERT outperforms logistic regression due to its ability to capture complex patterns and relationships in data, leveraging transformer architecture and pre-training on large text corpora. With a significantly larger number of parameters, BERT learns intricate features, enabling it to handle a wide range of tasks and achieve superior performance, especially in natural language understanding. Unlike logistic regression, BERT considers contextual information from the input sequence, understanding the meaning of words in the context of the entire sentence, which is crucial for tasks like sentiment analysis and text classification._**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3PQVxSa1Joh"
      },
      "outputs": [],
      "source": [
        "# The longest text in the data is 75 and we use it as the max_length\n",
        "max_length = 75\n",
        "x_train = bert_tokenizer(text_train,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train = np.array([1 if v == 'Android' else 0 for v in Y_train])\n",
        "\n",
        "x_test = bert_tokenizer(text_test,\n",
        "              max_length=75,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test = np.array([1 if v == 'Android' else 0 for v in Y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK7AMp0lZiG3",
        "outputId": "53e6be12-b1b4-4fdc-8c43-95651b391732"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x000001768FD91240> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function infer_framework at 0x000001768FD91240> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "82/82 [==============================] - 264s 3s/step - loss: 0.3358 - accuracy: 0.8581 - val_loss: 0.2745 - val_accuracy: 0.8973\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 247s 3s/step - loss: 0.1836 - accuracy: 0.9267 - val_loss: 0.2102 - val_accuracy: 0.9243\n",
            "82/82 [==============================] - 78s 947ms/step - loss: 0.1074 - accuracy: 0.9722\n",
            "Training Loss: 0.1074032410979271\n",
            "Training Accuracy: 0.9722329378128052\n",
            "6/6 [==============================] - 6s 922ms/step - loss: 0.2102 - accuracy: 0.9243\n",
            "Test Loss: 0.21019971370697021\n",
            "Test Accuracy: 0.9243243336677551\n"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "################################################################################\n",
        "\n",
        "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Load pre-trained BERT model for sequence classification\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=1)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = ['accuracy']\n",
        "bert_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "# Train\n",
        "history = bert_model.fit(x=dict(x_train), y=y_train, validation_data=(dict(x_test), y_test), epochs=2, batch_size=32)\n",
        "\n",
        "\n",
        "train_loss, train_accuracy = bert_model.evaluate(x_train, y_train)\n",
        "print(\"Training Loss:\", train_loss)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "\n",
        "test_loss, test_accuracy = bert_model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTj4FpQPEB6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtqVd8RMEB4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R49AgrskEB19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8jseSPKEByD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUoi2d94EBwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ActyA0lEBrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oOHJwEqpEBnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYKFYbplEBcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66COdz9sEBQC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05f44adfb4964ceaa3866ecbcfe93d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567958bbdc884b2886eb5dc0afbc9606",
            "placeholder": "",
            "style": "IPY_MODEL_4531a592df7e498681cc9f17da06c0cd",
            "value": "436M/436M[00:04&lt;00:00,157MB/s]"
          }
        },
        "065fa71c1ac44ce4999d75ad64993f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08ce1ff69e954d5bacc6b94edf9344d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90b6b9f984e74f1d8698f29a039e0fac",
            "placeholder": "",
            "style": "IPY_MODEL_492f34b402444c14afaedb7ff1be464e",
            "value": "213k/213k[00:00&lt;00:00,4.15MB/s]"
          }
        },
        "098be2c679f04237a6b532c192986e46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1695467872df4de1ab3f9005313b238f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b27509450046de923d6f510c32f408",
            "placeholder": "",
            "style": "IPY_MODEL_470049052bc74033ae8a56c833a9fbed",
            "value": "vocab.txt:100%"
          }
        },
        "20407c199d98484c8c5b8421bb28e729": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20cb9a60a488402e8b8b4ede244c689b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fde371c6e1c42ce9368ccbbc0f1f955",
            "placeholder": "",
            "style": "IPY_MODEL_3782cd35ae4f451b9035083937103a49",
            "value": "model.safetensors:100%"
          }
        },
        "263211072c3a4244a7651fe917a720e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778f819277e74ecb9c03f64fa670ef40",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fde7a6747ac94b1e9897535c32669502",
            "value": 49
          }
        },
        "263f8f6e0fde4d228c7bb150fc23ddf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d0fe0fac824a4e897d32772d514f20",
            "placeholder": "",
            "style": "IPY_MODEL_a4607b818f99416195d9a927654738ca",
            "value": "tokenizer.json:100%"
          }
        },
        "2bb34f1837344ec390fe7ce1ee846c41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9356996edb4325a2e1fb37cdd086a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3782cd35ae4f451b9035083937103a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c45b91044d24aa488c6cd73183ed272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45041e14756141f7a44f7006002231b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714041e86d6c4c4e8a6b334ab92f74f3",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_065fa71c1ac44ce4999d75ad64993f5e",
            "value": 435755784
          }
        },
        "4531a592df7e498681cc9f17da06c0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "470049052bc74033ae8a56c833a9fbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "492f34b402444c14afaedb7ff1be464e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4afd76e8ccb841cc990a8bbd9eff7297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb34f1837344ec390fe7ce1ee846c41",
            "placeholder": "",
            "style": "IPY_MODEL_20407c199d98484c8c5b8421bb28e729",
            "value": "49.0/49.0[00:00&lt;00:00,2.92kB/s]"
          }
        },
        "4fde371c6e1c42ce9368ccbbc0f1f955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5308f11014ee447ebb317e735022e176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "545f44b79ed44d1ba762b3df7b85fe55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d458c52405443eb07eea835efb68b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551b93d69cc84364807cb02a161d7180": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567958bbdc884b2886eb5dc0afbc9606": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f750b91de594832bbc1450331db3b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff600d4948f4aabacb8fcd82b1c6bc4",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab4bb3e86d9f4033a4b955aa8154a3d5",
            "value": 570
          }
        },
        "64b27509450046de923d6f510c32f408": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d0fe0fac824a4e897d32772d514f20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696d9a10019d4a398691f22c672e5582": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b625e232d148f98f1709ae07ee619c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a68d259fa2a4e1eb0c18231fea81021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714041e86d6c4c4e8a6b334ab92f74f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b6a7cf18e64ac1b80c889bed81f340": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb7078474f1c48afac5354dd1a39b47f",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bda0f1423cd4ba98e62a76b40375b00",
            "value": 435797
          }
        },
        "778f819277e74ecb9c03f64fa670ef40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bda0f1423cd4ba98e62a76b40375b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d019b5368aa454d886d042e7841cd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffd39daf4f4942ed8e3239086ba17ce8",
              "IPY_MODEL_263211072c3a4244a7651fe917a720e2",
              "IPY_MODEL_4afd76e8ccb841cc990a8bbd9eff7297"
            ],
            "layout": "IPY_MODEL_098be2c679f04237a6b532c192986e46"
          }
        },
        "7ddd9b1927b34f01acbf622847a17f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1695467872df4de1ab3f9005313b238f",
              "IPY_MODEL_c794b0da55ab4161b6c324ceb3b3da40",
              "IPY_MODEL_08ce1ff69e954d5bacc6b94edf9344d9"
            ],
            "layout": "IPY_MODEL_545f44b79ed44d1ba762b3df7b85fe55"
          }
        },
        "7ff600d4948f4aabacb8fcd82b1c6bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8184956211b14516989815ffc5d959d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e13cd7a4e584ca9b0c91f92df5c7673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6888f54b79c46fda753b97d17468ac2",
              "IPY_MODEL_5f750b91de594832bbc1450331db3b85",
              "IPY_MODEL_be55df80a2734f9db571ba06e1c9776d"
            ],
            "layout": "IPY_MODEL_54d458c52405443eb07eea835efb68b5"
          }
        },
        "8fa34397663e4c47b58c65c5811d0c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20cb9a60a488402e8b8b4ede244c689b",
              "IPY_MODEL_45041e14756141f7a44f7006002231b8",
              "IPY_MODEL_05f44adfb4964ceaa3866ecbcfe93d63"
            ],
            "layout": "IPY_MODEL_6a68d259fa2a4e1eb0c18231fea81021"
          }
        },
        "90b6b9f984e74f1d8698f29a039e0fac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "987a6b3c03b543c583b366cf34ab1021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b79a91e90824c42834b4957b74c3d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d9356996edb4325a2e1fb37cdd086a0",
            "placeholder": "",
            "style": "IPY_MODEL_69b625e232d148f98f1709ae07ee619c",
            "value": "436k/436k[00:00&lt;00:00,12.7MB/s]"
          }
        },
        "a4607b818f99416195d9a927654738ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab4bb3e86d9f4033a4b955aa8154a3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baa767a7f5eb4b4180f651ed8ede4f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be55df80a2734f9db571ba06e1c9776d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551b93d69cc84364807cb02a161d7180",
            "placeholder": "",
            "style": "IPY_MODEL_baa767a7f5eb4b4180f651ed8ede4f7b",
            "value": "570/570[00:00&lt;00:00,21.1kB/s]"
          }
        },
        "bf0fb1038d9940f1b283bd40a60341d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a809f53ecd47839cd9838e845618e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c40a2c1c00c94b5d92409a1b3764f28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_263f8f6e0fde4d228c7bb150fc23ddf2",
              "IPY_MODEL_75b6a7cf18e64ac1b80c889bed81f340",
              "IPY_MODEL_9b79a91e90824c42834b4957b74c3d7e"
            ],
            "layout": "IPY_MODEL_bf0fb1038d9940f1b283bd40a60341d0"
          }
        },
        "c6888f54b79c46fda753b97d17468ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696d9a10019d4a398691f22c672e5582",
            "placeholder": "",
            "style": "IPY_MODEL_c0a809f53ecd47839cd9838e845618e0",
            "value": "config.json:100%"
          }
        },
        "c794b0da55ab4161b6c324ceb3b3da40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987a6b3c03b543c583b366cf34ab1021",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c45b91044d24aa488c6cd73183ed272",
            "value": 213450
          }
        },
        "cb7078474f1c48afac5354dd1a39b47f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde7a6747ac94b1e9897535c32669502": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffd39daf4f4942ed8e3239086ba17ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8184956211b14516989815ffc5d959d4",
            "placeholder": "",
            "style": "IPY_MODEL_5308f11014ee447ebb317e735022e176",
            "value": "tokenizer_config.json:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}